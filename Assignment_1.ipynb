{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "for entry in sys.path:\n",
    "    if 'python2.7' in entry:\n",
    "        sys.path.remove(entry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.remove('/usr/local/lib/python2.7/site-packages/mxnet-0.9.1-py2.7-macosx-10.11-x86_64.egg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.image as mpimg\n",
    "import os\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from numpy import array\n",
    "import pickle\n",
    "\n",
    "def get_training_images():\n",
    "    training_images = ['train_data/{:05d}.jpg'.format(i) for i in range(1, 25113)]\n",
    "    training_images = [np.float32(mpimg.imread(img))/255 for img in training_images]\n",
    "    training_imgs = [img.flatten() for img in training_images]\n",
    "    training_imgs = [np.append(img, 1.0) for img in training_imgs]\n",
    "    return np.float32(np.array(training_imgs))\n",
    "\n",
    "def get_testing_images():\n",
    "    testing_images = ['test_data/{:04d}.jpg'.format(i) for i in range(1, 4983)]\n",
    "    testing_images = [np.float32(mpimg.imread(img))/255 for img in testing_images]\n",
    "    testing_imgs = [img.flatten() for img in testing_images]\n",
    "    testing_imgs = [np.append(img, 1.0) for img in testing_imgs]\n",
    "    return np.float32(np.array(testing_imgs))\n",
    "\n",
    "def get_training_label():\n",
    "    with open('labels/train_label.txt', 'r') as training_labels:\n",
    "        training_labels = training_labels.readlines()\n",
    "        new_training_labels = []\n",
    "        for i in training_labels:\n",
    "            new_training_labels.append(int(i.split('\\n')[0]))\n",
    "        training_values = array(new_training_labels)\n",
    "        onehot_encoder = OneHotEncoder()\n",
    "        label_encoder = LabelEncoder()\n",
    "        integer_encoded = label_encoder.fit_transform(training_values)\n",
    "        integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
    "    return np.float32(onehot_encoder.fit_transform(integer_encoded).toarray())\n",
    "\n",
    "def get_testing_label():\n",
    "    with open('labels/test_label.txt', 'r') as testing_labels:\n",
    "        testing_labels = testing_labels.readlines()\n",
    "        new_testing_labels = []\n",
    "        for i in testing_labels:\n",
    "            new_testing_labels.append(int(i.split('\\n')[0]))\n",
    "        testing_values = array(new_testing_labels)\n",
    "        onehot_encoder = OneHotEncoder()\n",
    "        label_encoder = LabelEncoder()\n",
    "        integer_encoded = label_encoder.fit_transform(testing_values)\n",
    "        integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
    "    return np.float32(onehot_encoder.fit_transform(integer_encoded).toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(785), Dimension(5)])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learning_rate = 0.01\n",
    "training_epochs = 20\n",
    "batch_size = 100\n",
    "display_step = 1\n",
    "\n",
    "# tf Graph Input\n",
    "x = tf.placeholder(tf.float32, [None,785]) # mnist data image of shape 28*28=784\n",
    "y = tf.placeholder(tf.float32, [None, 5]) # 0-9 digits recognition => 10 classes\n",
    "\n",
    "# Set model weights\n",
    "W = tf.Variable(tf.random_uniform([784, 5]))\n",
    "b = tf.Variable(tf.ones([1, 5]))\n",
    "theta = tf.Variable(tf.concat([W, b], 0), dtype=tf.float32)\n",
    "#theta = tf.cast(theta, dtype=tf.float32)\n",
    "theta.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-972e754a8d81>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msoftmax_logits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtheta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m         \u001b[0;31m#print third_part\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mnegative_one\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0minner_subtraction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubtract\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msoftmax_logits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mgradient\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minner_subtraction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtranspose_a\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tf' is not defined"
     ]
    }
   ],
   "source": [
    "softmax_logits = tf.nn.softmax(tf.matmul(tf.cast(x, tf.float32), tf.cast(theta, tf.float32)))\n",
    "        #print third_part\n",
    "negative_one = tf.constant(np.float32(-1))\n",
    "inner_subtraction = tf.subtract(y, softmax_logits)\n",
    "gradient = tf.matmul(x, inner_subtraction, transpose_a = True)\n",
    "gradient = tf.scalar_mul(negative_one, gradient)\n",
    "new_theta = tf.assign_sub(theta, tf.scalar_mul(learning_rate, gradient))\n",
    "\n",
    "# Construct model\n",
    "#pred = tf.nn.softmax(tf.matmul(x, theta)) # Softmax\n",
    "\n",
    "# Minimize error using cross entropy\n",
    "#cost = tf.reduce_mean(-tf.reduce_sum(y*tf.log(pred), reduction_indices=1))\n",
    "# Gradient Descent\n",
    "# Initialize the variables (i.e. assign their default value)\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.70687318]\n",
      "[0 0 0 ..., 0 2 2]\n",
      "[0.70232838]\n",
      "[0.70687318, 0.60576618]\n",
      "[1 1 4 ..., 1 1 4]\n",
      "[0.70232838, 0.58952224]\n",
      "[0.70687318, 0.60576618, 0.66784805]\n",
      "[2 2 2 ..., 2 2 2]\n",
      "[0.70232838, 0.58952224, 0.65455639]\n"
     ]
    }
   ],
   "source": [
    "# Start training\n",
    "training_error = []\n",
    "testing_error = []\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "\n",
    "    # Training cycle\n",
    "    for epoch in range(training_epochs):\n",
    "\n",
    "        train_data, train_labels = get_training_images(), get_training_label()\n",
    "            # Fit training using batch data\n",
    "        sess.run(new_theta, feed_dict={x: train_data, y: train_labels})\n",
    "            # Compute average loss\n",
    "            #avg_cost += c / total_batch\n",
    "        # Display logs per epoch step\n",
    "        #if (epoch+1) % display_step == 0:\n",
    "            #print \"Epoch:\", '%04d' % (epoch+1), \"theta=\", \"{:.9f}\".format(theta)\n",
    "        train_output = tf.matmul(train_data, theta)\n",
    "        train_output_softmax = tf.nn.softmax(train_output)\n",
    "        max_values_train = tf.argmax(train_output_softmax, axis = 1)\n",
    "        training_differences = tf.equal(tf.cast(max_values_train, tf.float32), tf.cast(tf.argmax(train_labels, axis=1), tf.float32))\n",
    "        training_accuracy_rate = tf.reduce_mean(tf.cast(training_differences, tf.float32))\n",
    "        training_error.append(sess.run(1 - training_accuracy_rate))\n",
    "        print(training_error)\n",
    "        \n",
    "        test_data = get_testing_images()\n",
    "        testing_labels = get_testing_label()\n",
    "        \n",
    "        test_output = tf.matmul(test_data, theta)\n",
    "        test_output_softmax = tf.nn.softmax(test_output)\n",
    "        max_values_test = tf.argmax(test_output_softmax, axis = 1)\n",
    "        differences = tf.equal(tf.cast(max_values_test, tf.float32), tf.cast(tf.argmax(testing_labels, axis=1), tf.float32))\n",
    "        \n",
    "        prediction = np.asarray(sess.run(max_values_test))\n",
    "        print(prediction)\n",
    "        testing_accuracy_rate = tf.reduce_mean(tf.cast(differences, tf.float32))\n",
    "        testing_error.append(sess.run(1 - testing_accuracy_rate))\n",
    "        print(testing_error)\n",
    "        testing_accuracy_rate = sess.run(testing_accuracy_rate)\n",
    "        if testing_accuracy_rate > 0.92:\n",
    "            np.savetxt(\"prediction.csv\", prediction, delimiter=\",\")\n",
    "    \n",
    "        \n",
    "    import pickle\n",
    "    final_theta = sess.run(theta)\n",
    "    filehandler = open(\"multiclass_parameters.txt\",\"wb\")\n",
    "    pickle.dump(final_theta, filehandler)\n",
    "    filehandler.close()   \n",
    "    \n",
    "    import matplotlib.pyplot as plt\n",
    "    for i in range(0, 5):\n",
    "        W_k = final_theta[0:784,i]\n",
    "        Img = W_k.reshape(28,28)\n",
    "        plt.savefig(\"Digits_Images.png\")\n",
    "        plt.colorbar()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(2,1,1)\n",
    "plt.plot(training_error, '-o', label='Training_Error')\n",
    "plt.title('Training Error')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Error')\n",
    "plt.legend(ncol=2, loc='upper right')\n",
    "plt.subplot(2,1,2)\n",
    "plt.plot(testing_error, '-o', label='Testing_Error')\n",
    "plt.title('Testing Error')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Error')\n",
    "plt.legend(ncol=2, loc='lower right')\n",
    "plt.gcf().set_size_inches(10, 10)\n",
    "plt.savefig('Training_and_testing_error.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
