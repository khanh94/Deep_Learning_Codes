{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "for entry in sys.path:\n",
    "    if 'python2.7' in entry:\n",
    "        sys.path.remove(entry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/khanh94/Downloads/youtube_action_train_data\n"
     ]
    }
   ],
   "source": [
    "cd youtube_action_train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'youtube_action_train_data_part1.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-2afb3d949b4f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;31m## read\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mtrain_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbytearray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0minput_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetsize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf_in\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_bytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.6/genericpath.py\u001b[0m in \u001b[0;36mgetsize\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mgetsize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0;34m\"\"\"Return the size of a file, reported by os.stat().\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mst_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'youtube_action_train_data_part1.pkl'"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import os.path\n",
    "\n",
    "#Load the training and testing data from the pickle files\n",
    "train_data_file = \"youtube_action_train_data_part1.pkl\"\n",
    "test_data_file = \"test_data.pkl\"\n",
    "train_label_file = \"train_out.pkl\"\n",
    "test_label_file = \"test_out.pkl\"\n",
    "n_bytes = 2**31\n",
    "max_bytes = 2**31 - 1\n",
    "data = bytearray(n_bytes)\n",
    "\n",
    "## write\n",
    "#bytes_out = pickle.dumps(data)\n",
    "#with open(file_path, 'wb') as f_out:\n",
    "#    for idx in range(0, n_bytes, max_bytes):\n",
    "#        f_out.write(bytes_out[idx:idx+max_bytes])\n",
    "\n",
    "## read\n",
    "train_data = bytearray(0)\n",
    "input_size = os.path.getsize(train_data_file)\n",
    "with open(train_data_file, 'rb') as f_in:\n",
    "    for _ in range(0, input_size, max_bytes):\n",
    "        train_data += f_in.read(max_bytes)\n",
    "train_data = pickle.loads(train_data)\n",
    "\n",
    "test_data = bytearray(0)\n",
    "input_size = os.path.getsize(test_data_file)\n",
    "with open(test_data_file, 'rb') as f_in:\n",
    "    for _ in range(0, input_size, max_bytes):\n",
    "        test_data += f_in.read(max_bytes)\n",
    "test_data = pickle.loads(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the training and testing labels from the pickle file\n",
    "train_label = bytearray(0)\n",
    "input_size = os.path.getsize(train_label_file)\n",
    "with open(train_label_file, 'rb') as f_in:\n",
    "    for _ in range(0, input_size, max_bytes):\n",
    "        train_label += f_in.read(max_bytes)\n",
    "train_label = pickle.loads(train_label)\n",
    "\n",
    "test_label = bytearray(0)\n",
    "input_size = os.path.getsize(test_label_file)\n",
    "with open(test_label_file, 'rb') as f_in:\n",
    "    for _ in range(0, input_size, max_bytes):\n",
    "        test_label += f_in.read(max_bytes)\n",
    "test_label = pickle.loads(test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2400, 10, 64, 64, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape\n",
    "test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5600, 10, 7, 2)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2400, 10, 7, 2)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_units = 128\n",
    "batch_size = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Placeholders\n",
    "X = tf.placeholder(shape=[None, 10, 64, 64, 3], dtype=tf.float32)\n",
    "Y_ = tf.placeholder(shape=[None, 10, 7, 2], dtype=tf.float32)\n",
    "lr = tf.placeholder(dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(None), Dimension(10), Dimension(30), Dimension(30), Dimension(32)])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Construct the Convolutional Neural Network\n",
    "conv1 = tf.layers.conv3d(inputs=X, filters=32, kernel_size=[1,5,5], strides=(1, 1, 1), padding='valid', activation=tf.nn.relu)\n",
    "conv1.shape\n",
    "pool2 = tf.layers.max_pooling3d(inputs=conv1, pool_size=[1, 2, 2], strides=(1, 2, 2))\n",
    "pool2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(None), Dimension(10), Dimension(26), Dimension(26), Dimension(32)])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv2 = tf.layers.conv3d(inputs=pool2, filters=32, kernel_size=[1,5,5], strides=(1, 1, 1), padding='valid', activation=tf.nn.relu)\n",
    "conv2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(None), Dimension(10), Dimension(13), Dimension(13), Dimension(32)])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pool3 = tf.layers.max_pooling3d(inputs=conv2, pool_size=[1, 2, 2], strides=(1, 2, 2))\n",
    "pool3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(None), Dimension(10), Dimension(11), Dimension(11), Dimension(64)])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv4 = tf.layers.conv3d(inputs=pool3, filters=64, kernel_size=[1,3,3], strides=(1, 1, 1), padding='valid', activation=tf.nn.relu)\n",
    "conv4.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pool5 = tf.layers.max_pooling3d(inputs=conv4, pool_size=[1, 2, 2], strides=(1, 2, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(None), Dimension(10), Dimension(5), Dimension(5), Dimension(64)])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pool5.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(None), Dimension(10), Dimension(1600)])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fully_connected = tf.reshape(pool5, (-1, 10, 1600))\n",
    "fully_connected.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(None), Dimension(10), Dimension(128)])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn_input = tf.layers.dense(inputs=fully_connected, units=num_units, activation=tf.nn.relu)\n",
    "rnn_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_cell = tf.nn.rnn_cell.LSTMCell(num_units)\n",
    "h_val, _ = tf.nn.dynamic_rnn(lstm_cell, rnn_input, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-935dbe75af74>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Feed the input to the RNN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mseq_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m30\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mfinal_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m14\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mw_fc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtruncated_normal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnum_units\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m14\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstddev\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'final_weight'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mb_fc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m14\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'last_bias'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tf' is not defined"
     ]
    }
   ],
   "source": [
    "#Feed the input to the RNN\n",
    "seq_length = 30\n",
    "final_output = tf.zeros(shape=[tf.shape(X)[0], 0, 14])\n",
    "w_fc = tf.Variable(tf.truncated_normal([num_units, 14], stddev=0.1), name='final_weight')\n",
    "b_fc = tf.Variable(tf.constant(0.1, tf.float32, [14]), name='last_bias')\n",
    "for i in np.arange(seq_length):\n",
    "    temp = tf.reshape(h_val[:, i, :], [-1, num_units])\n",
    "    output = tf.matmul(temp, w_fc) + b_fc\n",
    "    output = tf.reshape(output, [-1, 1, 14])\n",
    "    final_output = tf.concat([final_output, output], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(None), Dimension(10), Dimension(14)])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_output = tf.reshape(final_output, (-1, 10, 7, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(7)])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Calculate the mean squared loss and the average pixel distance for each image\n",
    "mean_squared_loss = tf.losses.mean_squared_error(labels=Y_, predictions=final_output)\n",
    "distance = tf.sqrt(tf.reduce_sum(tf.subtract(final_output, Y_)**2, axis = 3))\n",
    "average_distance = tf.reduce_mean(tf.reduce_mean(distance, axis = 1), axis = 0)\n",
    "average_distance.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training step, the learning rate is a placeholder\n",
    "train_step = tf.train.AdamOptimizer(lr).minimize(mean_squared_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 training loss: 842.066 (lr:0.0008)\n",
      "[ 36.81301117  44.47809982  54.71934891  44.51289368  55.26139832\n",
      "  38.34843826  45.72595596]\n",
      "0 test loss: 1093.98\n",
      "10 training loss: 851.002 (lr:0.0008)\n",
      "20 training loss: 812.326 (lr:0.0008)\n",
      "[ 32.54631042  38.35795593  49.62756729  39.97473526  49.19489288\n",
      "  35.4987793   41.8002243 ]\n",
      "20 test loss: 888.445\n",
      "30 training loss: 804.661 (lr:0.0008)\n",
      "40 training loss: 780.846 (lr:0.0008)\n",
      "[ 29.88226891  37.12385559  47.61646652  37.73807526  47.14468384\n",
      "  33.52452469  39.76183701]\n",
      "40 test loss: 804.751\n",
      "50 training loss: 633.242 (lr:0.0008)\n",
      "60 training loss: 609.308 (lr:0.0008)\n",
      "[ 28.13665771  35.31553268  45.83029938  36.22495651  45.68645859\n",
      "  31.44199181  37.80857086]\n",
      "60 test loss: 738.271\n",
      "70 training loss: 624.848 (lr:0.0008)\n",
      "80 training loss: 614.849 (lr:0.0008)\n",
      "[ 25.57921219  33.19661331  43.70502472  33.21260071  43.1999321\n",
      "  28.81017876  35.40890884]\n",
      "80 test loss: 653.503\n",
      "90 training loss: 472.107 (lr:0.0008)\n",
      "100 training loss: 473.911 (lr:0.0008)\n",
      "[ 24.17352486  31.48157883  40.99681091  32.38175201  40.80183792\n",
      "  27.17709732  33.37467957]\n",
      "100 test loss: 586.803\n",
      "110 training loss: 521.555 (lr:0.0008)\n",
      "120 training loss: 614.251 (lr:0.0008)\n",
      "[ 21.95282936  30.48560715  39.69311905  30.12722588  38.4058075\n",
      "  24.64120674  30.93233109]\n",
      "120 test loss: 523.491\n",
      "130 training loss: 559.682 (lr:0.0008)\n",
      "140 training loss: 435.32 (lr:0.0008)\n",
      "[ 20.94735909  27.34687805  38.1870842   28.37516022  37.31163406\n",
      "  23.46153641  29.89570808]\n",
      "140 test loss: 477.753\n",
      "150 training loss: 497.174 (lr:0.0008)\n",
      "160 training loss: 415.948 (lr:0.0008)\n",
      "[ 20.18699455  26.50156975  36.67916107  27.29108429  35.48532486\n",
      "  22.3965435   28.37765884]\n",
      "160 test loss: 441.186\n",
      "170 training loss: 379.439 (lr:0.0008)\n",
      "180 training loss: 355.856 (lr:0.0008)\n",
      "[ 17.42008018  23.42203331  34.77342606  24.8998909   33.78464508\n",
      "  19.90118217  26.19194794]\n",
      "180 test loss: 377.832\n",
      "190 training loss: 271.759 (lr:0.0008)\n",
      "200 training loss: 350.046 (lr:0.0008)\n",
      "[ 16.51655388  22.86153984  31.84115791  23.06721497  30.92346001\n",
      "  18.25059509  24.40341949]\n",
      "200 test loss: 329.954\n",
      "210 training loss: 313.659 (lr:0.0008)\n",
      "220 training loss: 172.49 (lr:0.0008)\n",
      "[ 14.70516014  19.06025314  29.52539825  19.78404617  28.40894318\n",
      "  15.84752464  22.0543499 ]\n",
      "220 test loss: 269.426\n",
      "230 training loss: 281.349 (lr:0.0008)\n",
      "240 training loss: 249.092 (lr:0.0008)\n",
      "[ 14.30303574  19.9131794   30.31900597  21.01795387  29.19383049\n",
      "  15.86979866  22.02165604]\n",
      "240 test loss: 282.71\n",
      "250 training loss: 273.932 (lr:0.0008)\n",
      "260 training loss: 161.286 (lr:0.0008)\n",
      "[ 12.90637112  17.6064949   27.50666046  18.71636581  26.95799065\n",
      "  14.16165447  20.10781097]\n",
      "260 test loss: 234.846\n",
      "270 training loss: 215.955 (lr:0.0008)\n",
      "280 training loss: 186.735 (lr:0.0008)\n",
      "[ 12.03931618  17.67485809  26.73292923  17.51520538  25.12965775\n",
      "  12.81902599  18.51579094]\n",
      "280 test loss: 214.14\n",
      "290 training loss: 105.674 (lr:0.0008)\n",
      "300 training loss: 160.965 (lr:0.0008)\n",
      "[ 12.06325436  16.78079605  25.049963    16.49131966  23.50741386\n",
      "  12.36247444  17.65719795]\n",
      "300 test loss: 193.897\n",
      "310 training loss: 221.026 (lr:0.0008)\n",
      "320 training loss: 168.185 (lr:0.0008)\n",
      "[  9.9817009   14.48332024  22.84271812  14.83467484  21.53686333\n",
      "  10.80778408  15.56424904]\n",
      "320 test loss: 158.718\n",
      "330 training loss: 133.515 (lr:0.0008)\n",
      "340 training loss: 165.974 (lr:0.0008)\n",
      "[  9.45910263  14.50847149  22.11536217  14.68631268  21.08760452\n",
      "  10.23422909  14.85541725]\n",
      "340 test loss: 152.447\n",
      "350 training loss: 147.727 (lr:0.0008)\n",
      "360 training loss: 98.3813 (lr:0.0008)\n",
      "[  8.95398331  13.82176495  21.84264565  12.98181534  19.00992966\n",
      "   9.11404514  13.38243198]\n",
      "360 test loss: 133.901\n",
      "370 training loss: 86.6255 (lr:0.0008)\n",
      "380 training loss: 84.8861 (lr:0.0008)\n",
      "[  8.96278858  12.9326086   20.84260559  12.57195473  19.19519806\n",
      "   9.40607834  13.59927368]\n",
      "380 test loss: 127.386\n",
      "390 training loss: 100.019 (lr:0.0008)\n",
      "400 training loss: 150.749 (lr:0.0008)\n",
      "[  7.76408672  13.204216    17.66528702  11.99186039  16.38420868\n",
      "   8.11296272  11.4800148 ]\n",
      "400 test loss: 104.007\n",
      "410 training loss: 93.5061 (lr:0.0008)\n",
      "420 training loss: 101.501 (lr:0.0008)\n",
      "[  7.9896102   12.78944111  17.35813141  11.84165668  16.16149902\n",
      "   8.44779491  11.37162399]\n",
      "420 test loss: 101.327\n",
      "430 training loss: 87.7182 (lr:0.0008)\n",
      "440 training loss: 115.158 (lr:0.0008)\n",
      "[  7.77980661  12.44482899  16.57415771  11.12816048  14.6605196\n",
      "   7.59100342  10.33085346]\n",
      "440 test loss: 90.4579\n",
      "450 training loss: 83.3781 (lr:0.0008)\n",
      "460 training loss: 53.3225 (lr:0.0008)\n",
      "[  7.29394817  12.54581642  17.12730217  11.18414688  14.73996735\n",
      "   7.57616806   9.96937084]\n",
      "460 test loss: 91.1803\n",
      "470 training loss: 106.529 (lr:0.0008)\n",
      "480 training loss: 70.6172 (lr:0.0008)\n",
      "[  7.44212484  11.91116714  16.22444534  10.75377178  14.86016273\n",
      "   8.23722649  10.38896275]\n",
      "480 test loss: 88.6204\n",
      "490 training loss: 68.1335 (lr:0.0008)\n",
      "500 training loss: 85.5093 (lr:0.0008)\n",
      "[  6.80719376  11.80728436  16.0135231   10.9128418   14.10438442\n",
      "   7.6695118    9.40688992]\n",
      "500 test loss: 82.921\n",
      "510 training loss: 80.1027 (lr:0.0008)\n",
      "520 training loss: 55.6689 (lr:0.0008)\n",
      "[  7.01053286  12.21362305  15.71859837  10.7786026   13.56927204\n",
      "   7.6004405    9.03801727]\n",
      "520 test loss: 80.5936\n",
      "530 training loss: 78.5351 (lr:0.0008)\n",
      "540 training loss: 50.5162 (lr:0.0008)\n",
      "[  6.57514668  11.76313591  15.78934479  10.38218307  13.23066044\n",
      "   7.28747606   8.75675678]\n",
      "540 test loss: 76.8255\n",
      "550 training loss: 62.3888 (lr:0.0008)\n",
      "560 training loss: 47.8082 (lr:0.0008)\n",
      "[  6.7432518   11.59550571  15.31663227  10.108531    12.59698963\n",
      "   7.08845472   8.17045975]\n",
      "560 test loss: 73.6369\n",
      "570 training loss: 70.2981 (lr:0.0008)\n",
      "580 training loss: 39.0174 (lr:0.0008)\n",
      "[  7.3693862   11.82903576  14.57351112  10.49779129  12.50618935\n",
      "   7.56046677   8.49918556]\n",
      "580 test loss: 74.2628\n",
      "590 training loss: 64.6052 (lr:0.0008)\n",
      "600 training loss: 54.4448 (lr:0.0008)\n",
      "[  6.56167459  12.14497662  13.85795403   9.55997086  11.43048954\n",
      "   6.88410521   7.67073345]\n",
      "600 test loss: 65.524\n",
      "610 training loss: 60.2661 (lr:0.0008)\n",
      "620 training loss: 52.6072 (lr:0.0008)\n",
      "[  6.63241005  12.19899368  14.88819313   9.62652016  11.34210968\n",
      "   6.63018942   7.31240606]\n",
      "620 test loss: 67.8388\n",
      "630 training loss: 82.0221 (lr:0.0008)\n",
      "640 training loss: 62.4909 (lr:0.0008)\n",
      "[  6.71726561  11.55820274  14.55436134  10.6398344   12.00836563\n",
      "   7.40313435   7.89444447]\n",
      "640 test loss: 70.2084\n",
      "650 training loss: 39.6101 (lr:0.0008)\n",
      "660 training loss: 58.3816 (lr:0.0008)\n",
      "[  7.1951251   12.15439129  14.16405392   9.43748283  10.71987057\n",
      "   7.18965197   7.68503761]\n",
      "660 test loss: 66.9897\n",
      "670 training loss: 41.0953 (lr:0.0008)\n",
      "680 training loss: 62.6361 (lr:0.0008)\n",
      "[  6.89425039  11.71246052  13.95938683   9.87507915  11.52832985\n",
      "   7.11950016   7.62341356]\n",
      "680 test loss: 66.2892\n",
      "690 training loss: 45.5365 (lr:0.0008)\n",
      "700 training loss: 60.0533 (lr:0.0008)\n",
      "[  6.63987875  12.0399332   14.13326168   9.48088932  10.95114613\n",
      "   7.08274221   7.49185991]\n",
      "700 test loss: 65.4343\n",
      "710 training loss: 56.0889 (lr:0.0008)\n",
      "720 training loss: 36.8057 (lr:0.0008)\n",
      "[  6.54694557  11.95487309  14.76266098  10.05440617  11.17847538\n",
      "   6.85383749   7.08884525]\n",
      "720 test loss: 66.6129\n",
      "730 training loss: 80.2496 (lr:0.0008)\n",
      "740 training loss: 45.2756 (lr:0.0008)\n",
      "[  6.22275925  11.20779896  13.6937952    9.39225197  10.85598373\n",
      "   7.04670525   7.46852493]\n",
      "740 test loss: 62.0598\n",
      "750 training loss: 52.8592 (lr:0.0008)\n",
      "760 training loss: 43.73 (lr:0.0008)\n",
      "[  7.03675604  11.83559704  14.10284424   9.70213795  10.63545036\n",
      "   7.17363787   7.31010628]\n",
      "760 test loss: 65.3694\n",
      "770 training loss: 51.1422 (lr:0.0008)\n",
      "780 training loss: 70.1974 (lr:0.0008)\n",
      "[  6.66189194  11.48523712  14.58050251   9.49857044  10.79796791\n",
      "   6.97029972   7.30073357]\n",
      "780 test loss: 64.3275\n",
      "790 training loss: 106.781 (lr:0.0008)\n",
      "800 training loss: 77.4808 (lr:0.0008)\n",
      "[  6.45536089  11.60351849  13.76093674   9.81700516  10.92045689\n",
      "   6.8489356    7.16189384]\n",
      "800 test loss: 62.6302\n",
      "810 training loss: 39.4767 (lr:0.0008)\n",
      "820 training loss: 56.8471 (lr:0.0008)\n",
      "[  6.9552083   12.10020542  14.53437519   9.65968609  10.84731579\n",
      "   7.37124157   7.64758301]\n",
      "820 test loss: 67.5429\n",
      "830 training loss: 55.2389 (lr:0.0008)\n",
      "840 training loss: 55.4344 (lr:0.0008)\n",
      "[  6.62661886  11.24807167  13.73863506   9.20832539  10.34336567\n",
      "   6.98154163   7.29427719]\n",
      "840 test loss: 61.0538\n",
      "850 training loss: 73.7179 (lr:0.0008)\n",
      "860 training loss: 86.6151 (lr:0.0008)\n",
      "[  6.55340147  11.69709587  13.9822073    9.33725452  10.84089851\n",
      "   6.84036827   7.19567871]\n",
      "860 test loss: 62.2918\n",
      "870 training loss: 92.6984 (lr:0.0008)\n",
      "880 training loss: 78.5384 (lr:0.0008)\n",
      "[  6.84649086  11.79960728  13.91302395   9.69070911  10.47696209\n",
      "   6.90957355   7.19210434]\n",
      "880 test loss: 63.2902\n",
      "890 training loss: 72.3672 (lr:0.0008)\n",
      "900 training loss: 54.8855 (lr:0.0008)\n",
      "[  6.70413399  11.68363571  13.89482307   9.99190712  10.86291218\n",
      "   7.33026934   7.53054523]\n",
      "900 test loss: 65.3867\n",
      "910 training loss: 84.823 (lr:0.0008)\n",
      "920 training loss: 57.6165 (lr:0.0008)\n",
      "[  6.67193651  11.46645546  14.36981297   8.81595707   9.98562622\n",
      "   6.33982468   6.65700674]\n",
      "920 test loss: 59.9696\n",
      "930 training loss: 68.9287 (lr:0.0008)\n",
      "940 training loss: 63.4184 (lr:0.0008)\n",
      "[  6.47462749  11.16714859  13.38720798   9.2048521   10.09578896\n",
      "   6.81697369   7.07011795]\n",
      "940 test loss: 58.2016\n",
      "950 training loss: 47.6963 (lr:0.0008)\n",
      "960 training loss: 66.3989 (lr:0.0008)\n",
      "[  6.91861677  11.29540253  13.66400719   9.60737514  10.56349087\n",
      "   7.00546408   7.16684866]\n",
      "960 test loss: 62.4157\n",
      "970 training loss: 53.4181 (lr:0.0008)\n",
      "980 training loss: 55.4555 (lr:0.0008)\n",
      "[  7.13567686  11.38510513  13.77597809  10.06326866  11.00453949\n",
      "   7.65533876   7.87072277]\n",
      "980 test loss: 65.6674\n",
      "990 training loss: 59.8333 (lr:0.0008)\n",
      "1000 training loss: 68.1166 (lr:0.0008)\n",
      "[  7.09632874  11.94213963  14.39021969  10.01740646  11.03519249\n",
      "   7.41293049   7.6594677 ]\n",
      "1000 test loss: 68.0418\n",
      "1010 training loss: 57.9528 (lr:0.0008)\n",
      "1020 training loss: 65.6681 (lr:0.0008)\n",
      "[  6.49487448  11.70972252  14.16292095   9.55341721  10.62571621\n",
      "   6.82483578   7.15167522]\n",
      "1020 test loss: 63.0961\n",
      "1030 training loss: 47.5522 (lr:0.0008)\n",
      "1040 training loss: 43.6932 (lr:0.0008)\n",
      "[  6.60050488  11.93124294  13.56158447   9.60582447  10.2193985\n",
      "   6.70728159   7.00455189]\n",
      "1040 test loss: 61.9452\n",
      "1050 training loss: 81.5864 (lr:0.0008)\n",
      "1060 training loss: 46.7521 (lr:0.0008)\n",
      "[  6.58057737  11.56502533  14.23532104   9.79340076  10.86968899\n",
      "   7.20182562   7.38526011]\n",
      "1060 test loss: 64.0357\n",
      "1070 training loss: 63.6662 (lr:0.0008)\n",
      "1080 training loss: 53.4626 (lr:0.0008)\n",
      "[  7.10403299  12.00015736  14.73535633  10.61545372  11.81125832\n",
      "   7.9787035    8.08275318]\n",
      "1080 test loss: 72.1284\n",
      "1090 training loss: 82.1557 (lr:0.0008)\n",
      "1100 training loss: 70.4863 (lr:0.0008)\n",
      "[  6.55156088  11.26554775  14.16516876   9.82726479  11.12920666\n",
      "   6.90300274   7.18050289]\n",
      "1100 test loss: 64.6245\n",
      "1110 training loss: 56.6509 (lr:0.0008)\n",
      "1120 training loss: 66.7698 (lr:0.0008)\n",
      "[  6.93674755  11.54388046  14.12388897  10.16818523  11.02832127\n",
      "   7.12001848   7.28792477]\n",
      "1120 test loss: 65.3657\n",
      "1130 training loss: 29.8754 (lr:0.0008)\n",
      "1140 training loss: 61.3033 (lr:0.0008)\n",
      "[  6.77239513  11.42334557  14.48157883   9.82832432  10.94879627\n",
      "   7.05133247   7.19993305]\n",
      "1140 test loss: 65.1676\n",
      "1150 training loss: 59.0399 (lr:0.0008)\n",
      "1160 training loss: 57.0176 (lr:0.0008)\n",
      "[  6.63444901  11.90529633  14.09483051   9.57598591  10.33484268\n",
      "   6.48627615   6.75935173]\n",
      "1160 test loss: 62.0519\n",
      "1170 training loss: 43.6874 (lr:0.0008)\n",
      "1180 training loss: 35.3052 (lr:0.0008)\n",
      "[  6.74675035  11.58421898  14.09517002   9.30238342  10.3245945\n",
      "   6.84990311   7.06907606]\n",
      "1180 test loss: 61.6115\n",
      "1190 training loss: 62.5277 (lr:0.0008)\n",
      "1200 training loss: 53.8685 (lr:0.0008)\n",
      "[  6.19892645  11.73145676  14.04417229   9.47499752  10.39976406\n",
      "   6.60970879   6.95046377]\n",
      "1200 test loss: 60.3461\n",
      "1210 training loss: 74.6167 (lr:0.0008)\n",
      "1220 training loss: 66.1382 (lr:0.0008)\n",
      "[  6.55724907  11.10641575  13.95610237   9.721735    10.81193447\n",
      "   6.84383583   7.17620468]\n",
      "1220 test loss: 61.7845\n",
      "1230 training loss: 48.9185 (lr:0.0008)\n",
      "1240 training loss: 48.0205 (lr:0.0008)\n",
      "[  6.47739792  11.65015411  13.59068203   9.4002676   10.21599102\n",
      "   6.77999449   7.10179138]\n",
      "1240 test loss: 60.3443\n",
      "1250 training loss: 62.3252 (lr:0.0008)\n",
      "1260 training loss: 54.6677 (lr:0.0008)\n",
      "[  6.53568172  11.68561268  13.45916462   9.6553812   10.4634409\n",
      "   6.89097309   7.167243  ]\n",
      "1260 test loss: 60.9674\n",
      "1270 training loss: 32.7142 (lr:0.0008)\n",
      "1280 training loss: 49.407 (lr:0.0008)\n",
      "[  6.43449593  11.63303185  14.11606693   9.79626751  11.04334068\n",
      "   6.97996378   7.46799374]\n",
      "1280 test loss: 64.0235\n",
      "1290 training loss: 61.7273 (lr:0.0008)\n",
      "1300 training loss: 41.9336 (lr:0.0008)\n",
      "[  6.55907917  12.06490707  14.80554295  10.17041302  11.26108646\n",
      "   6.98222542   7.31842041]\n",
      "1300 test loss: 67.378\n",
      "1310 training loss: 62.3504 (lr:0.0008)\n",
      "1320 training loss: 54.7936 (lr:0.0008)\n",
      "[  6.30772591  11.54349327  14.29168415   9.84052372  11.08115768\n",
      "   7.35602522   7.69584703]\n",
      "1320 test loss: 64.7031\n",
      "1330 training loss: 59.5002 (lr:0.0008)\n",
      "1340 training loss: 87.9614 (lr:0.0008)\n",
      "[  6.89741039  11.34273815  14.27686882  10.14994907  11.29664993\n",
      "   7.48553467   7.72954464]\n",
      "1340 test loss: 66.7987\n",
      "1350 training loss: 76.9679 (lr:0.0008)\n",
      "1360 training loss: 59.999 (lr:0.0008)\n",
      "[  7.4132843   12.13792229  13.50574684   9.72710609  10.37489891\n",
      "   7.60783815   7.7124896 ]\n",
      "1360 test loss: 65.6068\n",
      "1370 training loss: 69.8587 (lr:0.0008)\n",
      "1380 training loss: 57.7193 (lr:0.0008)\n",
      "[  6.38361406  10.86910629  13.40656471   9.55545807  10.81736374\n",
      "   6.89662743   7.36591816]\n",
      "1380 test loss: 59.8216\n",
      "1390 training loss: 54.2585 (lr:0.0008)\n",
      "1400 training loss: 67.2884 (lr:0.0008)\n",
      "[  7.039464    12.13556671  14.72519398  10.24466419  11.58369732\n",
      "   7.59831667   7.92721176]\n",
      "1400 test loss: 69.7764\n",
      "1410 training loss: 36.512 (lr:0.0008)\n",
      "1420 training loss: 34.4671 (lr:0.0008)\n",
      "[  6.96847057  11.8039999   13.60949612   9.50620461  10.21877861\n",
      "   6.90862989   6.93343306]\n",
      "1420 test loss: 61.6797\n",
      "1430 training loss: 52.5088 (lr:0.0008)\n",
      "1440 training loss: 46.3024 (lr:0.0008)\n",
      "[  6.84111309  11.34534836  14.16961193   9.78916264  10.70980072\n",
      "   6.75863075   6.91296148]\n",
      "1440 test loss: 62.7071\n",
      "1450 training loss: 41.7967 (lr:0.0008)\n",
      "1460 training loss: 78.6596 (lr:0.0008)\n",
      "[  6.75328684  11.31591702  13.51271439   9.69263268  10.51140499\n",
      "   7.09603167   7.40052223]\n",
      "1460 test loss: 60.9208\n",
      "1470 training loss: 65.6078 (lr:0.0008)\n",
      "1480 training loss: 52.2357 (lr:0.0008)\n",
      "[  7.23058891  11.78665733  14.07173538  10.28103161  10.91444683\n",
      "   7.67555857   7.65328407]\n",
      "1480 test loss: 67.0274\n",
      "1490 training loss: 43.9455 (lr:0.0008)\n",
      "1500 training loss: 66.3653 (lr:0.0008)\n",
      "[  6.71963644  11.81388092  14.55364037   9.64060211  11.04307175\n",
      "   7.2614131    7.5090003 ]\n",
      "1500 test loss: 65.7913\n",
      "1510 training loss: 37.386 (lr:0.0008)\n",
      "1520 training loss: 52.9251 (lr:0.0008)\n",
      "[  6.75890303  11.71382236  13.73863506   9.67386436  10.82587814\n",
      "   7.20541811   7.50172186]\n",
      "1520 test loss: 62.7433\n",
      "1530 training loss: 44.837 (lr:0.0008)\n",
      "1540 training loss: 53.6103 (lr:0.0008)\n",
      "[  6.41623116  11.61684322  13.34668541   9.44862938  10.16078091\n",
      "   6.77315187   7.12033558]\n",
      "1540 test loss: 59.3185\n",
      "1550 training loss: 74.0569 (lr:0.0008)\n",
      "1560 training loss: 75.296 (lr:0.0008)\n",
      "[  6.2446723   11.6726265   14.65567493   9.41604996  10.6859827\n",
      "   6.71057415   6.89576769]\n",
      "1560 test loss: 62.631\n",
      "1570 training loss: 62.3299 (lr:0.0008)\n",
      "1580 training loss: 58.3407 (lr:0.0008)\n",
      "[  6.4917202   11.63907337  14.11927128   9.59976578  10.69336414\n",
      "   6.86476183   7.09725523]\n",
      "1580 test loss: 62.6185\n",
      "1590 training loss: 74.4054 (lr:0.0008)\n",
      "1600 training loss: 53.0343 (lr:0.0008)\n",
      "[  6.49955702  11.20352173  13.68976116   9.9347229   10.98144817\n",
      "   6.94186354   7.24101877]\n",
      "1600 test loss: 61.8814\n",
      "1610 training loss: 74.5245 (lr:0.0008)\n",
      "1620 training loss: 67.9684 (lr:0.0008)\n",
      "[  7.01478434  11.88668919  14.52632046   9.67460251  10.86552525\n",
      "   7.29878044   7.66493464]\n",
      "1620 test loss: 66.7824\n",
      "1630 training loss: 73.6511 (lr:0.0008)\n",
      "1640 training loss: 87.7555 (lr:0.0008)\n",
      "[  6.89537907  11.25297928  14.01318932   9.42090607  10.62559319\n",
      "   7.53698063   7.7057271 ]\n",
      "1640 test loss: 62.7353\n",
      "1650 training loss: 43.1551 (lr:0.0008)\n",
      "1660 training loss: 56.4718 (lr:0.0008)\n",
      "[  6.8555007   11.80632687  13.85185814  10.07987118  10.94495487\n",
      "   7.36715078   7.37371397]\n",
      "1660 test loss: 64.8587\n",
      "1670 training loss: 101.927 (lr:0.0008)\n",
      "1680 training loss: 36.1598 (lr:0.0008)\n",
      "[  6.60717487  11.83253098  14.33027267   9.25215149  10.60284519\n",
      "   6.60353088   7.0485673 ]\n",
      "1680 test loss: 62.8638\n",
      "1690 training loss: 60.4131 (lr:0.0008)\n",
      "1700 training loss: 52.6877 (lr:0.0008)\n",
      "[  6.94876957  11.78345966  14.50983143   9.90452671  10.91558266\n",
      "   7.01440668   7.20305967]\n",
      "1700 test loss: 65.5985\n",
      "1710 training loss: 83.9634 (lr:0.0008)\n",
      "1720 training loss: 28.0266 (lr:0.0008)\n",
      "[  6.93239641  12.01074982  13.8666544   10.27804852  11.01758385\n",
      "   7.6373229    7.65070963]\n",
      "1720 test loss: 66.8177\n",
      "1730 training loss: 54.155 (lr:0.0008)\n",
      "1740 training loss: 68.4441 (lr:0.0008)\n",
      "[  6.8671279   11.75152111  14.36133385   9.49540997  10.50043678\n",
      "   7.07374334   7.28419542]\n",
      "1740 test loss: 65.0902\n",
      "1750 training loss: 45.6067 (lr:0.0008)\n",
      "1760 training loss: 89.1936 (lr:0.0008)\n",
      "[  6.87800884  11.4073143   14.79478645  10.10754013  11.34079361\n",
      "   7.52299309   7.72767496]\n",
      "1760 test loss: 68.2685\n",
      "1770 training loss: 60.7676 (lr:0.0008)\n",
      "1780 training loss: 32.2323 (lr:0.0008)\n",
      "[  6.96414566  12.48399448  14.46991539  10.14122772  10.77766228\n",
      "   6.94036484   7.04897833]\n",
      "1780 test loss: 66.5056\n",
      "1790 training loss: 43.1149 (lr:0.0008)\n",
      "1800 training loss: 31.244 (lr:0.0008)\n",
      "[  6.25339031  11.76467896  13.9274292    9.43579865  10.38659668\n",
      "   6.78103638   6.9817853 ]\n",
      "1800 test loss: 61.1323\n",
      "1810 training loss: 47.5113 (lr:0.0008)\n",
      "1820 training loss: 54.2532 (lr:0.0008)\n",
      "[  6.66547012  11.80165482  14.26403427   9.94705582  10.89886379\n",
      "   6.78357077   7.12850285]\n",
      "1820 test loss: 65.0436\n",
      "1830 training loss: 54.3303 (lr:0.0008)\n",
      "1840 training loss: 43.172 (lr:0.0008)\n",
      "[  6.92517328  11.51941395  13.83795738   9.90824986  11.00297356\n",
      "   7.40629196   7.58736229]\n",
      "1840 test loss: 64.2738\n",
      "1850 training loss: 45.2842 (lr:0.0008)\n",
      "1860 training loss: 51.2383 (lr:0.0008)\n",
      "[  6.37420225  11.39954948  12.98531246   9.28757     10.24316978\n",
      "   6.78133249   7.37962389]\n",
      "1860 test loss: 57.401\n",
      "1870 training loss: 45.8246 (lr:0.0008)\n",
      "1880 training loss: 33.1852 (lr:0.0008)\n",
      "[  6.63981771  12.13017845  14.50725842   9.88456821  10.61905289\n",
      "   7.0482769    7.19692278]\n",
      "1880 test loss: 65.2184\n",
      "1890 training loss: 72.0455 (lr:0.0008)\n",
      "1900 training loss: 64.0631 (lr:0.0008)\n",
      "[  6.91016054  11.32961273  14.19404507   9.85136318  11.06266212\n",
      "   7.00918579   7.35329485]\n",
      "1900 test loss: 64.7945\n",
      "1910 training loss: 84.0915 (lr:0.0008)\n",
      "1920 training loss: 61.4726 (lr:0.0008)\n",
      "[  6.92355347  11.52291393  13.60791111   9.67111969  10.98458767\n",
      "   7.5806303    7.77672243]\n",
      "1920 test loss: 64.1013\n",
      "1930 training loss: 58.9347 (lr:0.0008)\n",
      "1940 training loss: 97.7316 (lr:0.0008)\n",
      "[  6.3789978   11.84365749  14.10635757   9.86440754  11.17119503\n",
      "   7.10572338   7.56031179]\n",
      "1940 test loss: 64.6502\n",
      "1950 training loss: 82.9554 (lr:0.0008)\n",
      "1960 training loss: 54.7693 (lr:0.0008)\n",
      "[  6.60964918  11.23177147  13.90235138   8.78195953  10.21796036\n",
      "   6.64341354   7.28369188]\n",
      "1960 test loss: 59.6053\n",
      "1970 training loss: 48.3765 (lr:0.0008)\n",
      "1980 training loss: 79.8396 (lr:0.0008)\n",
      "[  6.9143815   11.40967274  13.97697639   9.54955769  10.54336071\n",
      "   7.07991171   7.38323927]\n",
      "1980 test loss: 63.1834\n",
      "1990 training loss: 52.313 (lr:0.0008)\n",
      "2000 training loss: 74.5588 (lr:0.0008)\n",
      "[  6.64183617  12.0960722   14.68764496   9.68848228  11.16168118\n",
      "   7.05583572   7.34215403]\n",
      "2000 test loss: 65.968\n",
      "2010 training loss: 65.3412 (lr:0.0008)\n",
      "2020 training loss: 78.5885 (lr:0.0008)\n",
      "[  6.45335531  11.75696182  13.76008987   9.88646984  10.60760212\n",
      "   6.96587324   7.10631084]\n",
      "2020 test loss: 62.7403\n",
      "2030 training loss: 49.8694 (lr:0.0008)\n",
      "2040 training loss: 58.0612 (lr:0.0008)\n",
      "[  6.82007885  12.32683182  14.47737694  10.31207848  11.27616119\n",
      "   7.07967234   7.44856071]\n",
      "2040 test loss: 66.9149\n",
      "2050 training loss: 63.6184 (lr:0.0008)\n",
      "2060 training loss: 52.0719 (lr:0.0008)\n",
      "[  7.01139641  11.47291374  13.30775738   9.56276226  10.57085896\n",
      "   7.34239435   7.46272469]\n",
      "2060 test loss: 62.7314\n",
      "2070 training loss: 53.4601 (lr:0.0008)\n",
      "2080 training loss: 36.584 (lr:0.0008)\n",
      "[  6.79284906  11.9003458   14.04871559   9.7899847   10.40981579\n",
      "   6.94458199   6.99076796]\n",
      "2080 test loss: 64.1251\n",
      "2090 training loss: 52.3518 (lr:0.0008)\n",
      "2100 training loss: 28.3303 (lr:0.0008)\n",
      "[  6.69111824  11.28744411  14.15146351   9.55058956  10.35148907\n",
      "   6.90109015   7.12244606]\n",
      "2100 test loss: 61.6156\n",
      "2110 training loss: 66.5051 (lr:0.0008)\n",
      "2120 training loss: 40.5015 (lr:0.0008)\n",
      "[  6.66597033  11.83886814  14.12252712   9.77015972  10.91166019\n",
      "   7.19408607   7.60615826]\n",
      "2120 test loss: 65.067\n",
      "2130 training loss: 70.5841 (lr:0.0008)\n",
      "2140 training loss: 67.912 (lr:0.0008)\n",
      "[  6.64821577  11.63608551  13.99896336   9.40103912  10.53827477\n",
      "   7.12010479   7.45794106]\n",
      "2140 test loss: 63.5869\n",
      "2150 training loss: 57.7383 (lr:0.0008)\n",
      "2160 training loss: 89.2285 (lr:0.0008)\n",
      "[  6.88901615  11.86420918  14.28091717   9.95123863  10.88512802\n",
      "   7.2087822    7.52453375]\n",
      "2160 test loss: 66.3421\n",
      "2170 training loss: 58.1792 (lr:0.0008)\n",
      "2180 training loss: 34.1303 (lr:0.0008)\n",
      "[  6.94742107  11.49800396  14.24179173   9.95840168  10.92118073\n",
      "   7.31783915   7.61961317]\n",
      "2180 test loss: 65.3873\n",
      "2190 training loss: 35.3069 (lr:0.0008)\n",
      "2200 training loss: 52.8941 (lr:0.0008)\n",
      "[  6.66167307  11.78436756  13.50317287   9.54444408  10.27228069\n",
      "   6.82907677   7.05286455]\n",
      "2200 test loss: 61.8468\n",
      "2210 training loss: 40.8149 (lr:0.0008)\n",
      "2220 training loss: 58.2075 (lr:0.0008)\n",
      "[  6.97813463  12.14836025  14.46126461  10.42058086  11.17265034\n",
      "   7.40468073   7.49326181]\n",
      "2220 test loss: 69.1261\n",
      "2230 training loss: 50.446 (lr:0.0008)\n",
      "2240 training loss: 52.812 (lr:0.0008)\n",
      "[  6.5421977   12.19469929  14.13964462   9.73685837  10.45075798\n",
      "   7.03656626   7.2392149 ]\n",
      "2240 test loss: 64.4159\n",
      "2250 training loss: 62.1192 (lr:0.0008)\n",
      "2260 training loss: 86.2014 (lr:0.0008)\n",
      "[  6.6791954   11.24256134  13.7438755    9.62757301  10.28730106\n",
      "   7.15714455   7.24243641]\n",
      "2260 test loss: 61.3343\n",
      "2270 training loss: 89.1262 (lr:0.0008)\n",
      "2280 training loss: 58.7885 (lr:0.0008)\n",
      "[  7.21931076  11.59421921  14.33134842  10.44683838  11.49708652\n",
      "   7.52720881   7.73644876]\n",
      "2280 test loss: 69.118\n",
      "2290 training loss: 56.7174 (lr:0.0008)\n",
      "2300 training loss: 77.9585 (lr:0.0008)\n",
      "[  6.65716267  11.55745506  14.08187389   9.16179752  10.35257339\n",
      "   6.36953115   6.82804251]\n",
      "2300 test loss: 60.4007\n",
      "2310 training loss: 52.0092 (lr:0.0008)\n",
      "2320 training loss: 33.2895 (lr:0.0008)\n",
      "[  6.87765551  11.82862091  14.08166218   9.76613045  11.00928593\n",
      "   7.1569972    7.42341566]\n",
      "2320 test loss: 65.556\n",
      "2330 training loss: 47.2837 (lr:0.0008)\n",
      "2340 training loss: 101.325 (lr:0.0008)\n",
      "[  6.83883429  11.40877819  14.06582355   9.47229099  10.56239891\n",
      "   6.79667473   7.19557428]\n",
      "2340 test loss: 62.1988\n",
      "2350 training loss: 48.6033 (lr:0.0008)\n",
      "2360 training loss: 39.8614 (lr:0.0008)\n",
      "[  6.8293705   11.59939575  13.85677242   9.59950447  10.95178604\n",
      "   7.16249371   7.39592791]\n",
      "2360 test loss: 64.1827\n",
      "2370 training loss: 60.4786 (lr:0.0008)\n",
      "2380 training loss: 44.4262 (lr:0.0008)\n",
      "[  7.25344563  11.13366222  13.29971886   9.77734756  10.58246136\n",
      "   7.55457115   7.81021309]\n",
      "2380 test loss: 62.5237\n",
      "2390 training loss: 36.5493 (lr:0.0008)\n",
      "2400 training loss: 49.929 (lr:0.0008)\n",
      "[  6.68774843  11.88580322  14.0234375   10.04992104  10.98492718\n",
      "   7.15517139   7.23347235]\n",
      "2400 test loss: 64.5569\n",
      "2410 training loss: 36.178 (lr:0.0008)\n",
      "2420 training loss: 57.6632 (lr:0.0008)\n",
      "[  6.54750538  11.13725567  14.42325687   9.83076763  11.13291168\n",
      "   6.89029551   7.17662096]\n",
      "2420 test loss: 63.6983\n",
      "2430 training loss: 47.2967 (lr:0.0008)\n",
      "2440 training loss: 59.4436 (lr:0.0008)\n",
      "[  7.0374012   11.6807642   13.94819355  10.04960442  10.85631752\n",
      "   7.37215376   7.54148006]\n",
      "2440 test loss: 65.7712\n",
      "2450 training loss: 58.5567 (lr:0.0008)\n",
      "2460 training loss: 46.2706 (lr:0.0008)\n",
      "[  6.80515814  11.52117538  14.07852745   9.88173199  10.85550785\n",
      "   7.28687143   7.44463968]\n",
      "2460 test loss: 64.3429\n",
      "2470 training loss: 58.3522 (lr:0.0008)\n",
      "2480 training loss: 64.4529 (lr:0.0008)\n",
      "[  6.82001209  12.31632614  14.70834923   9.7596035   10.915205\n",
      "   7.13348389   7.2221508 ]\n",
      "2480 test loss: 67.7099\n",
      "2490 training loss: 42.7655 (lr:0.0008)\n"
     ]
    }
   ],
   "source": [
    "#Get the relevant nodes and errors\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "tf.get_collection(\"validation_nodes\")\n",
    "# Add stuff to the collection.\n",
    "tf.add_to_collection(\"validation_nodes\", X)\n",
    "tf.add_to_collection(\"validation_nodes\", Y_)\n",
    "tf.add_to_collection(\"validation_nodes\", final_output)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "training_epochs = 2500\n",
    "learning_rate = 0.0008 \n",
    "\n",
    "#Get training error and losses\n",
    "training_error = []\n",
    "testing_error = []\n",
    "training_loss = []\n",
    "testing_loss = []\n",
    "training_joint_distance = []\n",
    "testing_joint_distance = []\n",
    "\n",
    "for i in range(training_epochs):\n",
    "    indices = np.random.randint(train_data.shape[0], size = 4)\n",
    "    batch_X = train_data[indices]\n",
    "    batch_Y = train_label[indices]\n",
    "    \n",
    "    test_indices = np.random.randint(test_data.shape[0],size = 100)\n",
    "    test_batch_X = test_data[test_indices]\n",
    "    test_batch_Y = test_label[test_indices]\n",
    "\n",
    "    # compute training values\n",
    "    if i % 10 == 0:\n",
    "        '''\n",
    "        When we sess.run here, we are calculating the accuracy and cross_entropy of the model on batch_X and batch_Y (ie. on 100 pieces of data)\n",
    "        '''\n",
    "        train_l, train_d = sess.run([mean_squared_loss, average_distance], {X: batch_X, Y_: batch_Y})\n",
    "        #temp = sess.run([correct_prediction], feed_dict={X: batch_X, Y_: batch_Y})\n",
    "        print(str(i) + \" training loss: \" + str(train_l) + \" (lr:\" + str(learning_rate) + \")\")\n",
    "        #training_error.append(train_l)\n",
    "        training_loss.append(train_l)\n",
    "        training_joint_distance.append(train_d)\n",
    " \n",
    "    # compute test values\n",
    "    if i % 20 == 0:\n",
    "        '''\n",
    "        When we sess.run here, we are calculating the accuracy and cross_entropy of the model on all of the data\n",
    "        '''\n",
    "        test_l, test_d = sess.run([mean_squared_loss, average_distance], {X: test_batch_X, Y_: test_batch_Y})\n",
    "        print(test_d)\n",
    "        print(str(i) + \" test loss: \" + str(test_l))\n",
    "        #testing_error.append(1 - a)\n",
    "        testing_loss.append(test_l)\n",
    "        testing_joint_distance.append(list(test_d))\n",
    "        \n",
    "    # the backpropagation training step\n",
    "    sess.run(train_step, {X: batch_X, Y_: batch_Y, lr: learning_rate})\n",
    "\n",
    "    if i % 1000 == 0:\n",
    "        saver = tf.train.Saver()\n",
    "        save_path = saver.save(sess, \"/Users/khanh94/Downloads/my_model_\" + str(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting the training and testing losses\n",
    "plt.subplot(2,1,1)\n",
    "plt.plot(training_loss, '-o', label='Training_Loss')\n",
    "plt.title('Training Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(ncol=2, loc='upper right')\n",
    "plt.subplot(2,1,2)\n",
    "plt.plot(testing_loss, '-o', label='Testing_Loss')\n",
    "plt.title('Testing Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(ncol=2, loc='lower right')\n",
    "plt.gcf().set_size_inches(10, 10)\n",
    "plt.savefig('Training_and_testing_loss.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAm4AAAJcCAYAAABAGii1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x18e218f588>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
